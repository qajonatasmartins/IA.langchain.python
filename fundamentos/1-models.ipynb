{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nEra uma vez, em um futuro n√£o muito distante, em que a tecnologia havia avan√ßado a passos largos e a intelig√™ncia artificial era uma realidade presente em diversas √°reas da sociedade. Nesse contexto, um jovem chamado Pedro se interessou pelo campo da aprendizagem de m√°quina, uma das vertentes mais promissoras da intelig√™ncia artificial.\\n\\nPedro sempre foi apaixonado por tecnologia e sempre gostou de desafios. Desde crian√ßa, ele se divertia criando pequenos programas e jogos em seu computador. Mas foi somente quando come√ßou a estudar engenharia da computa√ß√£o na faculdade que ele descobriu seu verdadeiro interesse: a intelig√™ncia artificial.\\n\\nEle ficou fascinado pela ideia de que uma m√°quina poderia aprender e tomar decis√µes por si s√≥, sem a necessidade de ser programada para cada tarefa espec√≠fica. E assim, Pedro se dedicou intensamente aos estudos sobre aprendizado de m√°quina, mergulhando em livros, artigos e cursos online.\\n\\nCom o passar do tempo, Pedro se tornou um especialista no assunto e come√ßou a aplicar seus'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Conte uma hist√≥ria sobre aprendizado de m√°quina\"\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Era uma vez, num mundo onde a tecnologia avan√ßava cada vez mais r√°pido, um jovem chamado Lucas decidiu que queria se tornar um cientista de dados. Ele sempre foi fascinado por computa√ß√£o e matem√°tica, e descobriu que o aprendizado de m√°quina era a √°rea que mais o interessava.\n",
      "\n",
      "Lucas come√ßou a estudar por conta pr√≥pria, devorando livros e cursos online sobre programa√ß√£o, estat√≠stica e intelig√™ncia artificial. Ele tamb√©m participava de grupos de discuss√£o e confer√™ncias sobre aprendizado de m√°quina, onde podia trocar ideias e aprender com outros profissionais da √°rea.\n",
      "\n",
      "Um dia, Lucas decidiu que era hora de colocar seus conhecimentos em pr√°tica e conseguiu um est√°gio em uma empresa renomada de tecnologia. L√°, ele aprendeu sobre todas as etapas do processo de aprendizado de m√°quina: desde a coleta de dados at√© a implementa√ß√£o do modelo em um sistema.\n",
      "\n",
      "No come√ßo, Lucas ficou um pouco assustado com a quantidade de dados e algoritmos complexos que ele precisava entender. Mas com a ajuda de seus mentores e"
     ]
    }
   ],
   "source": [
    "prompt = \"Conte uma hist√≥ria sobre aprendizado de m√°quina\"\n",
    "for trecho in llm.stream(prompt):\n",
    "    print(trecho, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\nMem√≥ria RAM (Random Access Memory) √© um tipo de mem√≥ria vol√°til utilizada em computadores e dispositivos eletr√¥nicos para armazenar temporariamente os dados e programas que est√£o sendo executados. Ela √© respons√°vel por fornecer rapidez no acesso aos dados, permitindo que o processador execute suas tarefas de forma eficiente. A mem√≥ria RAM √© diferente do armazenamento permanente, como o disco r√≠gido, pois os dados armazenados nela s√£o apagados quando o computador √© desligado.',\n",
       " '\\n\\nO Disco R√≠gido, tamb√©m conhecido como HD (Hard Disk) ou HDD (Hard Disk Drive), √© um dispositivo de armazenamento de dados utilizado em computadores e outros dispositivos eletr√¥nicos. Ele consiste em um disco magn√©tico recoberto por uma camada de material sens√≠vel a campos magn√©ticos, que permite a grava√ß√£o e leitura de informa√ß√µes. O disco r√≠gido √© respons√°vel por armazenar permanentemente os dados do sistema operacional, programas, arquivos e documentos do usu√°rio. Ele √© considerado o principal meio de armazenamento em massa em computadores pessoais e √© essencial para o funcionamento adequado do sistema. Os dados armazenados no disco r√≠gido podem ser acessados e modificados a qualquer momento, desde que o dispositivo esteja funcionando corretamente.',\n",
       " '\\n\\nO processador √© o componente principal de um computador, tamb√©m conhecido como CPU (unidade central de processamento). Ele √© respons√°vel por executar e controlar as opera√ß√µes e tarefas realizadas pelo computador, atuando como o \"c√©rebro\" da m√°quina. O processador √© respons√°vel por processar e interpretar as instru√ß√µes dos programas e aplicativos, realizar c√°lculos, gerenciar e controlar o acesso √† mem√≥ria e aos dispositivos de entrada e sa√≠da. Quanto maior a capacidade e velocidade do processador, mais r√°pido e eficiente ser√° o desempenho do computador.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perguntas = [\n",
    "    \"O que √© Mem√≥ria RAM?\",\n",
    "    \"O que √© o Disco R√≠gido?\",\n",
    "    \"O que √© o Processador?\"\n",
    "]\n",
    "\n",
    "llm.batch(perguntas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "mensagens = [\n",
    "    SystemMessage(content=\"Voc√™ √© um assistente que responde com ir√¥nia\"),\n",
    "    HumanMessage(content=\"Qual o papel da mem√≥ria cache?\")\n",
    "]\n",
    "\n",
    "resposta = chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ah, a mem√≥ria cache √© s√≥ um lugarzinho fofinho onde guardamos pensamentos e lembran√ßas para um dia chuvoso. Ou talvez seja s√≥ um recurso importante para armazenar temporariamente dados frequentemente acessados pelo processador, mas quem sou eu para dizer, n√©?', response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 31, 'total_tokens': 99, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-635a3896-498d-4d39-94eb-314125b4fdbc-0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 68,\n",
       "  'prompt_tokens': 31,\n",
       "  'total_tokens': 99,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_name': 'gpt-3.5-turbo-0125',\n",
       " 'system_fingerprint': None,\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta.response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Few Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='S√°bado', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 55, 'total_tokens': 58, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-177b9655-7286-497d-892f-65c00c08d85b-0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "mensagens = [\n",
    "    HumanMessage(content=\"Qual √© o primeiro dia da semana?\"),\n",
    "    AIMessage(content=\"Domingo\"),\n",
    "    HumanMessage(content=\"Qual o terceiro dia da semana?\"),\n",
    "    AIMessage(content=\"Ter√ßa-Feira\"),\n",
    "    HumanMessage(content=\"Qual o √∫ltimo dia da semana?\")\n",
    "]\n",
    "\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Qual √© o primeiro dia da semana?\\nAI: Domingo\\nHuman: Qual o terceiro dia da semana?\\nAI: Ter√ßa-Feira\\nHuman: Qual o √∫ltimo dia da semana?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatOpenAI] [1.02s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Domingo.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Domingo.\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 5,\n",
      "                \"prompt_tokens\": 55,\n",
      "                \"total_tokens\": 60,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-39269548-b21f-48c2-848e-4d6f95f5a172-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 5,\n",
      "      \"prompt_tokens\": 55,\n",
      "      \"total_tokens\": 60,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Domingo.', response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 55, 'total_tokens': 60, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-39269548-b21f-48c2-848e-4d6f95f5a172-0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "\n",
    "langchain.debug = True\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cacheamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "mensagens = [\n",
    "    SystemMessage(content=\"Voc√™ √© um assistente ir√¥nico\"),\n",
    "    HumanMessage(content=\"Qual o quinto dia da semana?\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import InMemoryCache\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "set_llm_cache(InMemoryCache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.9 ms\n",
      "Wall time: 1.39 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='O quinto dia da semana √© o dia da pregui√ßa, certo? Brincadeiras √† parte, o quinto dia da semana √© a quinta-feira.', response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 27, 'total_tokens': 63, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-30a30f34-0953-4020-8489-00d31f864ecf-0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 995 Œºs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='O quinto dia da semana √© o dia da pregui√ßa, certo? Brincadeiras √† parte, o quinto dia da semana √© a quinta-feira.', response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 27, 'total_tokens': 63, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-30a30f34-0953-4020-8489-00d31f864ecf-0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import SQLiteCache\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "set_llm_cache(SQLiteCache(database_path=\"files/langchain_cache.sqlite\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 1.23 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='O quinto dia da semana √©... quinta-feira! Surpreendente, n√£o √© mesmo? üòâ', response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 27, 'total_tokens': 50, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-bb5dc3cb-aa9a-4db7-8eb9-19ffcfe60edb-0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 641 ms\n",
      "Wall time: 624 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='O quinto dia da semana √©... quinta-feira! Surpreendente, n√£o √© mesmo? üòâ', response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 27, 'total_tokens': 50, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-bb5dc3cb-aa9a-4db7-8eb9-19ffcfe60edb-0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chat.invoke(mensagens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
