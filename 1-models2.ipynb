{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nEra uma vez, em um futuro próximo, em que a tecnologia avançada dominava o mundo, um jovem chamado Pedro se interessou pelo campo da inteligência artificial e decidiu se especializar em aprendizado de máquina.\\n\\nPedro era um estudante dedicado e sempre buscava aprender mais sobre o assunto. Ele frequentava aulas, participava de workshops e conferências e se mantinha atualizado com as últimas pesquisas e avanços na área.\\n\\nUm dia, ele foi convidado por um professor renomado para participar de um projeto de pesquisa em uma grande empresa de tecnologia. O objetivo do projeto era desenvolver um algoritmo de aprendizado de máquina capaz de prever o comportamento dos clientes de uma loja online e recomendar produtos personalizados para eles.\\n\\nPedro ficou muito animado com a oportunidade e se dedicou de corpo e alma ao projeto. Ele passava horas analisando dados, estudando algoritmos e testando diferentes modelos. Foi um desafio e tanto, mas ele estava determinado a fazer o melhor trabalho possível.\\n\\nCom o tempo, Pedro começou a ter resultados promissores. Se'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")\n",
    "\n",
    "prompt = (\"Conte uma história sobre aprendizado de maquina\")\n",
    "\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\nNão é possível responder a essa pergunta sem mais informações.',\n",
       " '\\n\\nDesculpe, não posso responder essa pergunta, pois não foi mencionado qual personagem está sendo referido.',\n",
       " '\\n\\nNão é possível determinar a idade do personagem sem mais informações sobre ele.',\n",
       " '\\n\\nNão é possível determinar a altura do personagem sem informações adicionais.',\n",
       " '\\n\\nNão é possível determinar o peso do personagem sem mais informações específicas sobre ele. Cada personagem pode ter características físicas diferentes que influenciam em seu peso, como altura, massa muscular, entre outros. ']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perguntas = [\n",
    "    \"Qual é o nome do personagem?\",\n",
    "    \"Qual é a cor do cabelo do personagem?\",\n",
    "    \"Qual é a idade do personagem?\",\n",
    "    \"Qual é a altura do personagem?\",\n",
    "    \"Qual é o peso do personagem?\",\n",
    "]\n",
    "\n",
    "llm.batch(perguntas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 36,\n",
       "  'prompt_tokens': 38,\n",
       "  'total_tokens': 74,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_name': 'gpt-3.5-turbo-0125',\n",
       " 'system_fingerprint': None,\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Você é um assistente de IA que responde perguntas de forma simples e objetiva.\"),\n",
    "    HumanMessage(content=\"Qual é o nome do personagem?\"),\n",
    "]\n",
    "\n",
    "resposta = chat.invoke(messages)\n",
    "resposta.content\n",
    "resposta.response_metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'segunda-feira.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "### Forma de treinar o modelo para responder perguntas de forma simples e objetiva \n",
    "messages = [\n",
    "    HumanMessage(content=\"Qual é o primeiro dia da semana?\"),\n",
    "    AIMessage(content=\"domingo.\"),\n",
    "    HumanMessage(content=\"Qual é o último dia da semana?\"),\n",
    "    AIMessage(content=\"sábado.\"),\n",
    "    HumanMessage(content=\"Qual é o segundo dia da semana?\"),\n",
    "]\n",
    "\n",
    "resposta = chat.invoke(messages)\n",
    "resposta.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Você é um assistente de IA que responde perguntas de forma simples e objetiva.\"),\n",
    "    HumanMessage(content=\"Qual é o nome do personagem?\"),\n",
    "]\n",
    "\n",
    "from langchain.cache import InMemoryCache\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "set_llm_cache(InMemoryCache())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.08 ms, sys: 1.34 ms, total: 7.43 ms\n",
      "Wall time: 722 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Desculpe, mas preciso de mais informações para poder responder à sua pergunta. Poderia fornecer mais detalhes ou contexto sobre o personagem ao qual você se refere?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "resposta = chat.invoke(messages)\n",
    "resposta.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 463 μs, sys: 20 μs, total: 483 μs\n",
      "Wall time: 482 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Desculpe, mas preciso de mais informações para poder responder à sua pergunta. Poderia fornecer mais detalhes ou contexto sobre o personagem ao qual você se refere?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "resposta = chat.invoke(messages)\n",
    "resposta.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import SQLiteCache\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "set_llm_cache(SQLiteCache(database_path=\"files/langchaincache.sqlite\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.9 ms, sys: 805 μs, total: 2.71 ms\n",
      "Wall time: 2.46 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Desculpe, mas você não especificou qual personagem está se referindo. Poderia fornecer mais informações para que eu possa ajudar melhor?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "resposta = chat.invoke(messages)\n",
    "resposta.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.09 ms, sys: 429 μs, total: 1.52 ms\n",
      "Wall time: 1.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Desculpe, mas você não especificou qual personagem está se referindo. Poderia fornecer mais informações para que eu possa ajudar melhor?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "resposta = chat.invoke(messages)\n",
    "resposta.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
